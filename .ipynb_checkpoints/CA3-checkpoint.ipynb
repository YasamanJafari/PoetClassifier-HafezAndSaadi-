{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CA3 - Naive Bayes Classification\n",
    "## Yasaman Jafari\n",
    "### 810195376"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, Naive Bayes is used to classify poems of two persian poets, \"Hafez\" and \"Saadi\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we read the data from .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>چون می‌رود این کشتی سرگشته که آخر</td>\n",
       "      <td>hafez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>که همین بود حد امکانش</td>\n",
       "      <td>saadi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ارادتی بنما تا سعادتی ببری</td>\n",
       "      <td>hafez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>خدا را زین معما پرده بردار</td>\n",
       "      <td>hafez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>گویی که در برابر چشمم مصوری</td>\n",
       "      <td>saadi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                text  label\n",
       "0  چون می‌رود این کشتی سرگشته که آخر  hafez\n",
       "1              که همین بود حد امکانش  saadi\n",
       "2         ارادتی بنما تا سعادتی ببری  hafez\n",
       "3         خدا را زین معما پرده بردار  hafez\n",
       "4        گویی که در برابر چشمم مصوری  saadi"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./Data/train_test.csv\", encoding=\"utf-8\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, we are provided with about 20000 samples and each one is labeled with its poet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "چون می‌رود این کشتی سرگشته که آخر\n"
     ]
    }
   ],
   "source": [
    "print(data[\"text\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to separate our data into two parts of train set and test set. Eighty percent of data is considered as train set.\n",
    "We need to shuffle the data and then choose 80% for train and leave the rest for test.\n",
    "\n",
    "We choose a random subset for train and test so that it is not sorted in any specific order and it can represent the entire poems collection better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.sample(frac = 0.8, random_state = 42)\n",
    "test = data.drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Percentage:  0.7999904255828426\n",
      "Test Percentage:  0.20000957441715736\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Percentage: \", len(train) / (len(test) + len(train)))\n",
    "print(\"Test Percentage: \", len(test) / (len(test) + len(train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3128</th>\n",
       "      <td>سه ماه می خور و نه ماه پارسا می‌باش</td>\n",
       "      <td>hafez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8157</th>\n",
       "      <td>زاهد بنگر نشسته دلتنگ</td>\n",
       "      <td>saadi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6682</th>\n",
       "      <td>ولیکن تا به چوگان می‌زنندش</td>\n",
       "      <td>saadi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11526</th>\n",
       "      <td>تا فخر دین عبدالصمد باشد که غمخواری کند</td>\n",
       "      <td>hafez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7477</th>\n",
       "      <td>تیغ جفا گر زنی ضرب تو آسایشست</td>\n",
       "      <td>saadi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          text  label\n",
       "3128       سه ماه می خور و نه ماه پارسا می‌باش  hafez\n",
       "8157                     زاهد بنگر نشسته دلتنگ  saadi\n",
       "6682                ولیکن تا به چوگان می‌زنندش  saadi\n",
       "11526  تا فخر دین عبدالصمد باشد که غمخواری کند  hafez\n",
       "7477             تیغ جفا گر زنی ضرب تو آسایشست  saadi"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to find all the words in the poems. For this I created a new column which keeps the list of words used in each poem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['index'] = train.index\n",
    "train['words'] = train.text.str.split().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>index</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3128</th>\n",
       "      <td>سه ماه می خور و نه ماه پارسا می‌باش</td>\n",
       "      <td>hafez</td>\n",
       "      <td>3128</td>\n",
       "      <td>[سه, ماه, می, خور, و, نه, ماه, پارسا, می‌باش]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8157</th>\n",
       "      <td>زاهد بنگر نشسته دلتنگ</td>\n",
       "      <td>saadi</td>\n",
       "      <td>8157</td>\n",
       "      <td>[زاهد, بنگر, نشسته, دلتنگ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6682</th>\n",
       "      <td>ولیکن تا به چوگان می‌زنندش</td>\n",
       "      <td>saadi</td>\n",
       "      <td>6682</td>\n",
       "      <td>[ولیکن, تا, به, چوگان, می‌زنندش]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11526</th>\n",
       "      <td>تا فخر دین عبدالصمد باشد که غمخواری کند</td>\n",
       "      <td>hafez</td>\n",
       "      <td>11526</td>\n",
       "      <td>[تا, فخر, دین, عبدالصمد, باشد, که, غمخواری, کند]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7477</th>\n",
       "      <td>تیغ جفا گر زنی ضرب تو آسایشست</td>\n",
       "      <td>saadi</td>\n",
       "      <td>7477</td>\n",
       "      <td>[تیغ, جفا, گر, زنی, ضرب, تو, آسایشست]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          text  label  index  \\\n",
       "3128       سه ماه می خور و نه ماه پارسا می‌باش  hafez   3128   \n",
       "8157                     زاهد بنگر نشسته دلتنگ  saadi   8157   \n",
       "6682                ولیکن تا به چوگان می‌زنندش  saadi   6682   \n",
       "11526  تا فخر دین عبدالصمد باشد که غمخواری کند  hafez  11526   \n",
       "7477             تیغ جفا گر زنی ضرب تو آسایشست  saadi   7477   \n",
       "\n",
       "                                                  words  \n",
       "3128      [سه, ماه, می, خور, و, نه, ماه, پارسا, می‌باش]  \n",
       "8157                         [زاهد, بنگر, نشسته, دلتنگ]  \n",
       "6682                   [ولیکن, تا, به, چوگان, می‌زنندش]  \n",
       "11526  [تا, فخر, دین, عبدالصمد, باشد, که, غمخواری, کند]  \n",
       "7477              [تیغ, جفا, گر, زنی, ضرب, تو, آسایشست]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to find all the words used in the set, I combined all the lists and then converted it to a set in order to remove duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some words are commonly used in persian and are not useful in classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['دل', 'گر', 'ما', 'هر', 'با', 'ای', 'سر', 'تا', 'چو', 'نه']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I'll separate train data of Hafez and Saadi to do some process on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hafez Count:  6753\n",
      "Saadi Count:  9958\n"
     ]
    }
   ],
   "source": [
    "hafez_train = train[train['label'] == \"hafez\"].drop(['text', 'label', 'index'], axis=1)\n",
    "saadi_train = train[train['label'] == \"saadi\"].drop(['text', 'label', 'index'], axis=1)\n",
    "\n",
    "print(\"Hafez Count: \", len(hafez_train))\n",
    "print(\"Saadi Count: \", len(saadi_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll consider each word as a feature. For this purpose, I need to find all distinct words in the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distinct_words_count:  12645\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "for poem in train['words']:\n",
    "    words += poem\n",
    "words = list(set(words))\n",
    "print(\"distinct_words_count: \", len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find_prob() function is used to we need to find the conditional probability of each word given the poet. For each word we need to find the number of occurances of it in a poet's poems and divide it by the total number of words used by that poet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_prob(hafez_train, saadi_train):\n",
    "    hafez_words = []\n",
    "    for poem in hafez_train['words']:\n",
    "        hafez_words += poem\n",
    "    print(\"Hafez_count: \", len(hafez_words))\n",
    "    \n",
    "    saadi_words = []\n",
    "    for poem in saadi_train['words']:\n",
    "        saadi_words += poem\n",
    "    print(\"Saadi_count: \", len(saadi_words))\n",
    "    \n",
    "    train_all_word_count = pd.DataFrame(columns=['hafez_count', 'saadi_count'])\n",
    "    for word in words:\n",
    "        train_all_word_count = train_all_word_count.append({'word': word, 'hafez_count': hafez_words.count(word), 'saadi_count': saadi_words.count(word)}, ignore_index=True)\n",
    "        \n",
    "    train_all_word_count = train_all_word_count.set_index('word')\n",
    "    train_all_word_count['hafez_prob'] = train_all_word_count['hafez_count'] / train_all_word_count['hafez_count'].sum()\n",
    "    train_all_word_count['saadi_prob'] = train_all_word_count['saadi_count'] / train_all_word_count['saadi_count'].sum()\n",
    "    \n",
    "    return train_all_word_count, hafez_words, saadi_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hafez_count:  50650\n",
      "Saadi_count:  70650\n"
     ]
    }
   ],
   "source": [
    "train_all_word_count, hafez_words, saadi_words = find_prob(hafez_train, saadi_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hafez_count</th>\n",
       "      <th>saadi_count</th>\n",
       "      <th>hafez_prob</th>\n",
       "      <th>saadi_prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>دلربا</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.41543e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>داده</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7.89733e-05</td>\n",
       "      <td>4.24628e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>مجموعه‌ای</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.97433e-05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>داریدم</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.41543e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>غزال</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.97433e-05</td>\n",
       "      <td>2.83086e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          hafez_count saadi_count   hafez_prob   saadi_prob\n",
       "word                                                       \n",
       "دلربا               0           1            0  1.41543e-05\n",
       "داده                4           3  7.89733e-05  4.24628e-05\n",
       "مجموعه‌ای           1           0  1.97433e-05            0\n",
       "داریدم              0           1            0  1.41543e-05\n",
       "غزال                1           2  1.97433e-05  2.83086e-05"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_all_word_count.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prior probabilities are calculated below. The prior probability of each poets in the total number of that poet's poems divided by all poems by both poets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hafez Probability:  0.4041050804859075\n",
      "Saadi Probability:  0.5958949195140926\n"
     ]
    }
   ],
   "source": [
    "hafez_prob = len(hafez_train) / (len(hafez_train) + len(saadi_train))\n",
    "saadi_prob = len(saadi_train) / (len(hafez_train) + len(saadi_train))\n",
    "\n",
    "print(\"Hafez Probability: \", hafez_prob)\n",
    "print(\"Saadi Probability: \", saadi_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this step, we will eliminate the words which are only used once by Hafez or Saadi as they cannot be distinctive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_all_word_count['all_count'] = train_all_word_count['hafez_count'] + train_all_word_count['saadi_count']\n",
    "# one_occurance = train_all_word_count[train_all_word_count['all_count'] == 1]\n",
    "# once_used = list(one_occurance.index)\n",
    "# words = list(set(words) - set(once_used))\n",
    "\n",
    "# train_all_word_count = find_prob()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operate On Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have built our model and need to predict the poet of the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>index</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>رفتی و همچنان به خیال من اندری</td>\n",
       "      <td>saadi</td>\n",
       "      <td>9</td>\n",
       "      <td>[رفتی, و, همچنان, به, خیال, من, اندری]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>آنجا که تویی رفتن ما سود ندارد</td>\n",
       "      <td>saadi</td>\n",
       "      <td>11</td>\n",
       "      <td>[آنجا, که, تویی, رفتن, ما, سود, ندارد]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>اندرونم با تو می‌آید ولیک</td>\n",
       "      <td>saadi</td>\n",
       "      <td>13</td>\n",
       "      <td>[اندرونم, با, تو, می‌آید, ولیک]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>که خوش آهنگ و فرح بخش هوایی دارد</td>\n",
       "      <td>hafez</td>\n",
       "      <td>16</td>\n",
       "      <td>[که, خوش, آهنگ, و, فرح, بخش, هوایی, دارد]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ناودان چشم رنجوران عشق</td>\n",
       "      <td>saadi</td>\n",
       "      <td>24</td>\n",
       "      <td>[ناودان, چشم, رنجوران, عشق]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                text  label  index  \\\n",
       "9     رفتی و همچنان به خیال من اندری  saadi      9   \n",
       "11    آنجا که تویی رفتن ما سود ندارد  saadi     11   \n",
       "13         اندرونم با تو می‌آید ولیک  saadi     13   \n",
       "16  که خوش آهنگ و فرح بخش هوایی دارد  hafez     16   \n",
       "24            ناودان چشم رنجوران عشق  saadi     24   \n",
       "\n",
       "                                        words  \n",
       "9      [رفتی, و, همچنان, به, خیال, من, اندری]  \n",
       "11     [آنجا, که, تویی, رفتن, ما, سود, ندارد]  \n",
       "13            [اندرونم, با, تو, می‌آید, ولیک]  \n",
       "16  [که, خوش, آهنگ, و, فرح, بخش, هوایی, دارد]  \n",
       "24                [ناودان, چشم, رنجوران, عشق]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['index'] = test.index\n",
    "test['words'] = test.text.str.split().to_frame()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Naive Bayes, we have the strong assumption of independence between each two features.\n",
    "\n",
    "So, the probability of each poet given the words is proportional to the multiplication of all the probabilities of each word given the poet multiplied by the prior probability which is the probability of each poet in general.\n",
    "\n",
    "After calculating this probability for Hafez and Saadi, we compare them and decide based on the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df):\n",
    "    for index, row in df.iterrows(): \n",
    "        curr_hafez_prob = len(hafez_train) / (len(hafez_train) + len(saadi_train))\n",
    "        curr_saadi_prob = len(saadi_train) / (len(hafez_train) + len(saadi_train))\n",
    "        for word in set(row[\"words\"]):\n",
    "            if word in words:\n",
    "                curr_hafez_prob *= train_all_word_count.at[word, 'hafez_prob']\n",
    "                curr_saadi_prob *= train_all_word_count.at[word, 'saadi_prob']\n",
    "        df.at[index, 'hafez_prob'] = curr_hafez_prob\n",
    "        df.at[index, 'saadi_prob'] = curr_saadi_prob\n",
    "\n",
    "    df['prediction_is_hafez'] = df['hafez_prob'] >= df['saadi_prob']\n",
    "\n",
    "    prediction_poet = {True: 'hafez', False: 'saadi'}\n",
    "    df['prediction'] = df['prediction_is_hafez'].map(prediction_poet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>index</th>\n",
       "      <th>words</th>\n",
       "      <th>hafez_prob</th>\n",
       "      <th>saadi_prob</th>\n",
       "      <th>prediction_is_hafez</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>رفتی و همچنان به خیال من اندری</td>\n",
       "      <td>saadi</td>\n",
       "      <td>9</td>\n",
       "      <td>[رفتی, و, همچنان, به, خیال, من, اندری]</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.067397e-21</td>\n",
       "      <td>False</td>\n",
       "      <td>saadi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>آنجا که تویی رفتن ما سود ندارد</td>\n",
       "      <td>saadi</td>\n",
       "      <td>11</td>\n",
       "      <td>[آنجا, که, تویی, رفتن, ما, سود, ندارد]</td>\n",
       "      <td>2.686915e-23</td>\n",
       "      <td>5.948826e-22</td>\n",
       "      <td>False</td>\n",
       "      <td>saadi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>اندرونم با تو می‌آید ولیک</td>\n",
       "      <td>saadi</td>\n",
       "      <td>13</td>\n",
       "      <td>[اندرونم, با, تو, می‌آید, ولیک]</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.970144e-16</td>\n",
       "      <td>False</td>\n",
       "      <td>saadi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>که خوش آهنگ و فرح بخش هوایی دارد</td>\n",
       "      <td>hafez</td>\n",
       "      <td>16</td>\n",
       "      <td>[که, خوش, آهنگ, و, فرح, بخش, هوایی, دارد]</td>\n",
       "      <td>7.862324e-25</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>True</td>\n",
       "      <td>hafez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ناودان چشم رنجوران عشق</td>\n",
       "      <td>saadi</td>\n",
       "      <td>24</td>\n",
       "      <td>[ناودان, چشم, رنجوران, عشق]</td>\n",
       "      <td>4.217595e-06</td>\n",
       "      <td>8.562444e-06</td>\n",
       "      <td>False</td>\n",
       "      <td>saadi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                text  label  index  \\\n",
       "9     رفتی و همچنان به خیال من اندری  saadi      9   \n",
       "11    آنجا که تویی رفتن ما سود ندارد  saadi     11   \n",
       "13         اندرونم با تو می‌آید ولیک  saadi     13   \n",
       "16  که خوش آهنگ و فرح بخش هوایی دارد  hafez     16   \n",
       "24            ناودان چشم رنجوران عشق  saadi     24   \n",
       "\n",
       "                                        words    hafez_prob    saadi_prob  \\\n",
       "9      [رفتی, و, همچنان, به, خیال, من, اندری]  0.000000e+00  6.067397e-21   \n",
       "11     [آنجا, که, تویی, رفتن, ما, سود, ندارد]  2.686915e-23  5.948826e-22   \n",
       "13            [اندرونم, با, تو, می‌آید, ولیک]  0.000000e+00  1.970144e-16   \n",
       "16  [که, خوش, آهنگ, و, فرح, بخش, هوایی, دارد]  7.862324e-25  0.000000e+00   \n",
       "24                [ناودان, چشم, رنجوران, عشق]  4.217595e-06  8.562444e-06   \n",
       "\n",
       "    prediction_is_hafez prediction  \n",
       "9                 False      saadi  \n",
       "11                False      saadi  \n",
       "13                False      saadi  \n",
       "16                 True      hafez  \n",
       "24                False      saadi  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(test)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to evaluate how good our model is, we use:\n",
    "* Recall\n",
    "* Precision\n",
    "* Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(df):\n",
    "    df['correct'] = (df['label'] == df['prediction'])\n",
    "    correct_count = (df['correct']).sum()\n",
    "    correct_hafez = (df[['correct', 'prediction_is_hafez']].all(axis='columns')).sum()\n",
    "    all_hafez = (df['label'] == 'hafez').sum()\n",
    "    all_hafez_detected = (df['prediction'] == 'hafez').sum()\n",
    "    accuracy = correct_count / len(test)\n",
    "    precision = correct_hafez / all_hafez_detected\n",
    "    recall = correct_hafez / all_hafez\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  0.7225225225225225\n",
      "Precision:  0.7229567307692307\n",
      "Accuracy:  0.7790808999521303\n"
     ]
    }
   ],
   "source": [
    "evaluate(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laplace Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a word is used only in one poet's work, the probability of it given the other poet, will be zero and as we multiply the probabilities, the result will be zero not considering any other features.\n",
    "\n",
    "In order to fix this, we add a fixed alpha to the count of all words in its poet's collection and add count * alpha  to the denominator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.5\n",
    "train_all_word_count['hafez_prob'] = (train_all_word_count['hafez_count'] + alpha) / (train_all_word_count['hafez_count'].sum() + (len(set(hafez_words))* alpha))\n",
    "train_all_word_count['saadi_prob'] = (train_all_word_count['saadi_count'] + alpha) / (train_all_word_count['saadi_count'].sum() + (len(set(saadi_words))* alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9687487047705816"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_all_word_count['hafez_prob'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  0.7561561561561562\n",
      "Precision:  0.7639563106796117\n",
      "Accuracy:  0.8097175682144567\n"
     ]
    }
   ],
   "source": [
    "evaluate(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distinct_words_count:  14084\n",
      "Hafez_count:  63077\n",
      "Saadi_count:  88560\n"
     ]
    }
   ],
   "source": [
    "data['index'] = data.index\n",
    "data['words'] = data.text.str.split().to_frame()\n",
    "\n",
    "hafez_data = data[data['label'] == \"hafez\"].drop(['text', 'label', 'index'], axis=1)\n",
    "saadi_data = data[data['label'] == \"saadi\"].drop(['text', 'label', 'index'], axis=1)\n",
    "words = []\n",
    "for poem in data['words']:\n",
    "    words += poem\n",
    "words = list(set(words))\n",
    "print(\"distinct_words_count: \", len(words))\n",
    "\n",
    "train_all_word_count, hafez_words, saadi_words = find_prob(hafez_data, saadi_data)\n",
    "\n",
    "eval_data = pd.read_csv(\"./Data/evaluate.csv\", encoding=\"utf-8\")\n",
    "\n",
    "alpha = 0.5\n",
    "train_all_word_count['hafez_prob'] = (train_all_word_count['hafez_count'] + alpha) / (train_all_word_count['hafez_count'].sum() + (len(set(hafez_words)) * alpha))\n",
    "train_all_word_count['saadi_prob'] = (train_all_word_count['saadi_count'] + alpha) / (train_all_word_count['saadi_count'].sum() + (len(set(saadi_words)) * alpha))\n",
    "\n",
    "eval_data['index'] = eval_data.id\n",
    "eval_data['words'] = eval_data.text.str.split().to_frame()\n",
    "\n",
    "predict(eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>index</th>\n",
       "      <th>words</th>\n",
       "      <th>hafez_prob</th>\n",
       "      <th>saadi_prob</th>\n",
       "      <th>prediction_is_hafez</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ور بی تو بامداد کنم روز محشر است</td>\n",
       "      <td>1</td>\n",
       "      <td>[ور, بی, تو, بامداد, کنم, روز, محشر, است]</td>\n",
       "      <td>4.218360e-26</td>\n",
       "      <td>8.332959e-24</td>\n",
       "      <td>False</td>\n",
       "      <td>saadi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ساقی بیار جامی کز زهد توبه کردم</td>\n",
       "      <td>2</td>\n",
       "      <td>[ساقی, بیار, جامی, کز, زهد, توبه, کردم]</td>\n",
       "      <td>3.170615e-23</td>\n",
       "      <td>1.437545e-25</td>\n",
       "      <td>True</td>\n",
       "      <td>hafez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>مرا هرآینه خاموش بودن اولی‌تر</td>\n",
       "      <td>3</td>\n",
       "      <td>[مرا, هرآینه, خاموش, بودن, اولی‌تر]</td>\n",
       "      <td>4.178083e-22</td>\n",
       "      <td>2.454424e-20</td>\n",
       "      <td>False</td>\n",
       "      <td>saadi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>تو ندانی که چرا در تو کسی خیره بماند</td>\n",
       "      <td>4</td>\n",
       "      <td>[تو, ندانی, که, چرا, در, تو, کسی, خیره, بماند]</td>\n",
       "      <td>6.959319e-25</td>\n",
       "      <td>7.154032e-23</td>\n",
       "      <td>False</td>\n",
       "      <td>saadi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>کاینان به دل ربودن مردم معینند</td>\n",
       "      <td>5</td>\n",
       "      <td>[کاینان, به, دل, ربودن, مردم, معینند]</td>\n",
       "      <td>1.621379e-23</td>\n",
       "      <td>5.822081e-22</td>\n",
       "      <td>False</td>\n",
       "      <td>saadi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                  text  index  \\\n",
       "0   1      ور بی تو بامداد کنم روز محشر است      1   \n",
       "1   2       ساقی بیار جامی کز زهد توبه کردم      2   \n",
       "2   3         مرا هرآینه خاموش بودن اولی‌تر      3   \n",
       "3   4  تو ندانی که چرا در تو کسی خیره بماند      4   \n",
       "4   5        کاینان به دل ربودن مردم معینند      5   \n",
       "\n",
       "                                            words    hafez_prob    saadi_prob  \\\n",
       "0       [ور, بی, تو, بامداد, کنم, روز, محشر, است]  4.218360e-26  8.332959e-24   \n",
       "1         [ساقی, بیار, جامی, کز, زهد, توبه, کردم]  3.170615e-23  1.437545e-25   \n",
       "2             [مرا, هرآینه, خاموش, بودن, اولی‌تر]  4.178083e-22  2.454424e-20   \n",
       "3  [تو, ندانی, که, چرا, در, تو, کسی, خیره, بماند]  6.959319e-25  7.154032e-23   \n",
       "4           [کاینان, به, دل, ربودن, مردم, معینند]  1.621379e-23  5.822081e-22   \n",
       "\n",
       "   prediction_is_hafez prediction  \n",
       "0                False      saadi  \n",
       "1                 True      hafez  \n",
       "2                False      saadi  \n",
       "3                False      saadi  \n",
       "4                False      saadi  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({\n",
    "    \"id\": eval_data['index'],\n",
    "    \"label\": eval_data['prediction'],\n",
    "})\n",
    "output.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>saadi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>hafez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>saadi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>saadi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>saadi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label\n",
       "0   1  saadi\n",
       "1   2  hafez\n",
       "2   3  saadi\n",
       "3   4  saadi\n",
       "4   5  saadi"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report Questions and Explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my algorithm, each distinct word is considered a feature.\n",
    "\n",
    "Bayesian probability consists of 4 parts:\n",
    "* Prior\n",
    "* Posterior\n",
    "* Likelihood\n",
    "* Evidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(Poet|W_0, W_1, W_2, ...,  W_n) = \\frac{P(Poet)P(W_0, W_1, W_2, ...,  W_n|Poet)}{P(W_0, W_1, W_2, ...,  W_n)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the equation above, we have:\n",
    "* Prior: P(Poet)\n",
    "* Likelihood: P(W0, W1, W2, ..., Wn|Poet)\n",
    "* Evidence: P(W0, W1, W2, ..., Wn)\n",
    "* Posterior: P(Poet|W0, W1, W2, ..., Wn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, Prior is the probability of each poet in general, this means how probable it is for a poem to be for a certain poet in general not considering any other data. In order to calculate the prior, for each poet, we divide the number of that poet's poems by the number of all given poems.\n",
    " \n",
    "Likelihood is the probability of each word of a poem given the poet. In Naive Bayes, each feature is independent of others, so this is the multiplication of the probabilities of each word given the poet. This means how probable it is for a certain poet to use that word. To calculate this, we multiply the probabilities of each word given the poet. The probaility of each word given the poet is the number of times that word is used in that poet's works divided by the total number of words in that poet's work.\n",
    "\n",
    "Evidence is the probabiliy of all words that we have in a given poem. We do not need to calculate this as it is the same for both poets and does not change the result of comparison. If we wanted to calculate this, we could multiply the probabilites of all words. The probability of each word is the number of its occurance divided by the count of all words.\n",
    "\n",
    "Posterior is the probaility of a poet given the words in a poem. We use bayesian rule stated below to calculate this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(c|X) = \\frac{P(c)\\times\\prod_{i=1}^{m} P(x_i|c)}{P(X)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. What is the problem if we only use precision to evaluate our model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we only use precision for model evaluation, we can get a 100 percent precision if we manage to correctly guess only one poem of the corresponding poet, and predict the other poet for all other given poems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Precision = \\frac{True Positive}{True Positive + False Positive} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words if we are able to predict one of Hafez's poems correctly and assign it to Hafez and then assign all the other poems to Saadi, the precision for Hafez will be 100%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Why isn't accuracy enough for evaluating the model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the majority of the data belongs to a specific class, accuracy will not be a good measure to evaluate our model. \n",
    "For instance if we want to predict if a person has cancer or not, the majority of people do not have cancer and we can simply predict that no one has cancer and we will get a high accuracy as we have detected almost every case correctly but the model is not good at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laplace "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having a word which only exists in one of the poet's work in the training data, the probaility of that word given the other poet will be zero and as we consider the multiplication of these probabilities, the result will be zero ignoring all other probabilities, so the given poet will not be assigned to this poet. \n",
    "\n",
    "In order to fix this, I added a small alpha to the count of each word while calculating the corresponding probability. I also added count * alpha to denominator in order to have the sum of 1 for the new probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance the percentages before laplace is shown below in one case:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Recall:  0.7213213213213213\n",
    "* Precision:  0.7200239808153477\n",
    "* Accuracy:  0.7771661081857348"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After Laplace:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Recall:  0.7645645645645646\n",
    "* Precision:  0.755938242280285\n",
    "* Accuracy:  0.8078027764480613"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, all the percentages have improved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
